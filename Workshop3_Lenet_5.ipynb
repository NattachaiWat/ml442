{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Workshop3_Lenet-5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NattachaiWat/ml442/blob/master/Workshop3_Lenet_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5fXvnXJBhtF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Workshop 3.2 - Lenet-5 as Sequential API\n",
        "\n",
        "Let's create a Lenet-5 CNN. \n",
        "\n",
        "You fill in the blanks (replace the ??), make sure it passes the Python interpreter, and then verify it's "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvyVV5DY_Urh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j4YHR7SCD1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Input Parameters { form-width: \"400px\", display-mode: \"both\"}\n",
        "#@markdown --------------------------------------------------\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense,Flatten\n",
        "\n",
        "\n",
        "# Let's start with a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Let's assume we are building a model for MNIST, which are 28x28 Gray images\n",
        "# HINT: how many channels are in an RGB image\n",
        "input_shape=(28,28,1)\n",
        "\n",
        "\n",
        "#@markdown Layer 1: Conv2D\n",
        "\n",
        "#@markdown Let's add a first convolution layer with 6 filters(5x5), strides=1 \n",
        "#@markdown and zeropadding \n",
        "layer1_filter_number = None #@param {type:\"integer\"}\n",
        "layer1_filter_size   = None #@param {type:\"integer\"}\n",
        "layer1_filter_stride = None #@param {type:\"integer\"}\n",
        "layer1_filter_pad = \"same\" #@param [\"same\", \"valid\"]\n",
        "\n",
        "model.add(Conv2D(filters=layer1_filter_number, \n",
        "                 kernel_size=(layer1_filter_size,layer1_filter_size), \n",
        "                 strides=1, activation='relu',\n",
        "                 padding=layer1_filter_pad, \n",
        "                 input_shape=input_shape))\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 2: MaxPooling2D\n",
        "\n",
        "#@markdown HINT: 2x2 window and move 2 pixels at a time\n",
        "layer2_maxpool_size = None #@param {type:\"integer\"}\n",
        "layer2_maxpool_stride = None #@param {type:\"integer\"}\n",
        "model.add(MaxPooling2D(pool_size=(layer2_maxpool_size,layer2_maxpool_size), \n",
        "                       strides=layer2_maxpool_stride))\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 3: Conv2D\n",
        "\n",
        "#@markdown Let's add a second convolution layer with 16 filters(5x5), strides=1\n",
        "layer3_filter_number = None #@param {type:\"integer\"}\n",
        "layer3_filter_size   = None #@param {type:\"integer\"}\n",
        "layer3_filter_stride = None #@param {type:\"integer\"}\n",
        "\n",
        "model.add(Conv2D(filters=layer3_filter_number, \n",
        "                 kernel_size=(layer3_filter_size,layer3_filter_size), \n",
        "                 strides=layer3_filter_stride, \n",
        "                 activation='relu'))\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 4: MaxPooling2D\n",
        "\n",
        "#@markdown HINT: 2x2 window and move 2 pixels at a time\n",
        "layer4_maxpool_size = None #@param {type:\"integer\"}\n",
        "layer4_maxpool_stride = None #@param {type:\"integer\"}\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=layer4_maxpool_size, \n",
        "                       strides=layer4_maxpool_stride))\n",
        "model.add(Flatten())\n",
        "\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 5: Fully Connect Layer\n",
        "\n",
        "#@markdown Try to change them\n",
        "layer5_fc1_node = None #@param {type:\"integer\"}\n",
        "\n",
        "model.add(Dense(layer5_fc1_node, activation='relu'))\n",
        "\n",
        "# Output node for 10 classes\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "#@markdown --------------------------------------------------\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfaTuznvFjAQ",
        "colab_type": "text"
      },
      "source": [
        "### Verify the model architecture using summary method\n",
        "\n",
        "It should look like below:\n",
        "```\n",
        "Model: \"sequential_1\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d_2 (Conv2D)            (None, 28, 28, 6)         156       \n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 6)         0         \n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 10, 10, 16)        2416      \n",
        "_________________________________________________________________\n",
        "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 16)          0         \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 400)               0         \n",
        "_________________________________________________________________\n",
        "dense_3 (Dense)              (None, 84)                33684     \n",
        "_________________________________________________________________\n",
        "dense_4 (Dense)              (None, 10)                850       \n",
        "=================================================================\n",
        "Total params: 37,106\n",
        "Trainable params: 37,106\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNNClvTGGmJI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Let's import the builtin datasets for\n",
        "    MNIST: 28x28 images, 10 classes, Training 60000 images (6000 per class) validating 10000 samples (1000 per class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_z6pGAKD4j_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9sH4KDCHyjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Load MNIST Dataset{ form-width: \"400px\", display-mode: \"both\" }\n",
        "#@markdown Images have to be normalizated with 255.\n",
        "\n",
        "normalize_params = None #@param {type:\"number\"}\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train/normalize_params\n",
        "x_test = x_test/normalize_params\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhdFpccbLgZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Expanding dimenstion { form-width: \"400px\", display-mode: \"both\" }\n",
        "#@markdown Convert the (None,28,28) to (None,28,28,1)\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-HEj60qIIED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Printing the final input shape ready for training { form-width: \"400px\", display-mode: \"both\" }\n",
        "print(\"Train matrix shape\", x_train.shape)\n",
        "print(\"Test matrix shape\", x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucsXh8HdIv93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Making output to be one hot-encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#@markdown Enter the number of class\n",
        "num_class = None #@param {type:\"integer\"}\n",
        "Y_hot_enc_train = to_categorical(y_train,num_classes=num_class)\n",
        "Y_hot_enc_test  = to_categorical(y_test,num_classes=num_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9V4CHACNFx7",
        "colab_type": "text"
      },
      "source": [
        "# Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sMaaxBrI_OX",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Compile our model { vertical-output: true }\n",
        "#@markdown Enter loss function:\n",
        "loss_name   = '' #@param {type:'string'}\n",
        "\n",
        "#@markdown Enter evaluation metric:\n",
        "metric_name = '' #@param {type:'string'}\n",
        "\n",
        "#@markdown Enter Optimizer function:\n",
        "optimization_func = \"sgd\" #@param [\"sgd\", \"adam\"]\n",
        "\n",
        "\n",
        "model.compile(loss=loss_name, \n",
        "              metrics=[metric_name], \n",
        "              optimizer=optimization_func)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLZ-nICkJYg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training our model { vertical-output: true }\n",
        "#@markdown Enter Batchsize:\n",
        "batch_size = None  #@param {type:'integer'}\n",
        "\n",
        "#@markdown Enter number of epoch:\n",
        "n_epochs = None  #@param {type:'integer'}\n",
        "\n",
        "#@markdown ----------------------------------\n",
        "# training the model and saving metrics in history\n",
        "history = model.fit(x_train, Y_hot_enc_train,\n",
        "          batch_size=batch_size, epochs=n_epochs,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test, Y_hot_enc_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFzJ1_aHNS4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Showing Loss { vertical-output: true }\n",
        "import matplotlib.pylab as plt\n",
        "train_loss = history.history['loss']\n",
        "val_loss   = history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"#epoch\")\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.legend(['train','test'])\n",
        "plt.title('Loss')\n",
        "plt.grid(True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLwado0HQAB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Showing Accuracy { vertical-output: true }\n",
        "train_acc  = history.history['accuracy']\n",
        "val_acc    = history.history['val_accuracy']\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"#epoch\")\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.legend(['train','test'])\n",
        "plt.title('Loss')\n",
        "plt.grid(True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf9d9VVrNNdF",
        "colab_type": "text"
      },
      "source": [
        "# Save and Restore Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbpyeTSKJq4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Save model\n",
        "import time\n",
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "tf.keras.experimental.export_saved_model(model, export_path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2WDDyErUIek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Loading model for prediction\n",
        "reloaded_model = tf.keras.experimental.load_from_saved_model(export_path)\n",
        "print(reloaded_model.predict(x_test[:1,:,:,:]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzZtAZr_NRTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Resume for training model again\n",
        "#@markdown Enter loss function:\n",
        "loss_name   = '' #@param {type:'string'}\n",
        "\n",
        "#@markdown Enter evaluation metric:\n",
        "metric_name = '' #@param {type:'string'}\n",
        "\n",
        "#@markdown Enter Optimizer function:\n",
        "optimization_func = \"sgd\" #@param [\"sgd\", \"adam\"]\n",
        "\n",
        "reloaded_model.compile(optimizer=optimization_func,\n",
        "                 loss=loss_name,\n",
        "                 metrics=[metric_name])\n",
        "\n",
        "loss_and_metrics = reloaded_model.evaluate(x_test, \n",
        "                                           Y_hot_enc_test, \n",
        "                                           verbose=2)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}