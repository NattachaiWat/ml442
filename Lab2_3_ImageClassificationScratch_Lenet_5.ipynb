{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab2.3_ImageClassificationScratch_Lenet-5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NattachaiWat/ml442/blob/batch4/Lab2_3_ImageClassificationScratch_Lenet_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5fXvnXJBhtF",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## Workshop 4 - Lenet-5 as Sequential API\n",
        "\n",
        "Let's create a Lenet-5 CNN. \n",
        "\n",
        "You fill in the blanks (replace the ??), make sure it passes the Python interpreter, and then verify it's "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvyVV5DY_Urh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j4YHR7SCD1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Input Parameters { form-width: \"45%\", display-mode: \"both\" }\n",
        "#@markdown --------------------------------------------------\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense,Flatten\n",
        "\n",
        "\n",
        "# Let's start with a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Let's assume we are building a model for MNIST, which are 28x28 Gray images\n",
        "# HINT: how many channels are in an RGB image\n",
        "#@markdown Enter input shape\n",
        "input_shape= None #@param\n",
        "\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 1: Conv2D\n",
        "\n",
        "#@markdown Let's add a first convolution layer with 6 filters(5x5), strides=1 \n",
        "#@markdown and zeropadding \n",
        "layer1_filter_number = None #@param {type:\"integer\"}\n",
        "layer1_filter_size   = None  #@param {type:\"integer\"}\n",
        "layer1_filter_stride =   None #@param {type:\"integer\"}\n",
        "layer1_filter_pad = \"same\" #@param [\"same\", \"valid\"]\n",
        "\n",
        "model.add(Conv2D(filters=layer1_filter_number, \n",
        "                 kernel_size=(layer1_filter_size,layer1_filter_size), \n",
        "                 strides=1, activation='relu',\n",
        "                 padding=layer1_filter_pad, \n",
        "                 input_shape=input_shape))\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 2: MaxPooling2D\n",
        "\n",
        "#@markdown HINT: 2x2 window and move 2 pixels at a time\n",
        "layer2_maxpool_size =  None #@param {type:\"integer\"}\n",
        "layer2_maxpool_stride = None  #@param {type:\"integer\"}\n",
        "model.add(MaxPooling2D(pool_size=(layer2_maxpool_size,layer2_maxpool_size), \n",
        "                       strides=layer2_maxpool_stride))\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 3: Conv2D\n",
        "\n",
        "#@markdown Let's add a second convolution layer with 16 filters(5x5), strides=1\n",
        "layer3_filter_number =   None#@param {type:\"integer\"}\n",
        "layer3_filter_size   =   None#@param {type:\"integer\"}\n",
        "layer3_filter_stride =   None#@param {type:\"integer\"}\n",
        "\n",
        "model.add(Conv2D(filters=layer3_filter_number, \n",
        "                 kernel_size=(layer3_filter_size,layer3_filter_size), \n",
        "                 strides=layer3_filter_stride, \n",
        "                 activation='relu'))\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 4: MaxPooling2D\n",
        "\n",
        "#@markdown HINT: 2x2 window and move 2 pixels at a time\n",
        "layer4_maxpool_size =  None #@param {type:\"integer\"}\n",
        "layer4_maxpool_stride =  None#@param {type:\"integer\"}\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=layer4_maxpool_size, \n",
        "                       strides=layer4_maxpool_stride))\n",
        "model.add(Flatten())\n",
        "\n",
        "#@markdown --------------------------------------------------\n",
        "#@markdown Layer 5: Fully Connect Layer\n",
        "\n",
        "#@markdown Try to change them\n",
        "layer5_fc1_node =  None #@param {type:\"integer\"}\n",
        "\n",
        "model.add(Dense(layer5_fc1_node, activation='relu'))\n",
        "\n",
        "# Output node for 10 classes\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "#@markdown --------------------------------------------------\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfaTuznvFjAQ",
        "colab_type": "text"
      },
      "source": [
        "### Verify the model architecture using summary method\n",
        "\n",
        "It should look like below:\n",
        "```\n",
        "Model: \"sequential_1\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d_2 (Conv2D)            (None, 28, 28, 6)         156       \n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 6)         0         \n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 10, 10, 16)        2416      \n",
        "_________________________________________________________________\n",
        "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 16)          0         \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 400)               0         \n",
        "_________________________________________________________________\n",
        "dense_3 (Dense)              (None, 84)                33684     \n",
        "_________________________________________________________________\n",
        "dense_4 (Dense)              (None, 10)                850       \n",
        "=================================================================\n",
        "Total params: 37,106\n",
        "Trainable params: 37,106\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNNClvTGGmJI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Let's import the builtin datasets for\n",
        "    MNIST: 28x28 images, 10 classes, Training 60000 images (6000 per class) validating 10000 samples (1000 per class)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_z6pGAKD4j_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9sH4KDCHyjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Load MNIST Dataset{ form-width: \"400px\", display-mode: \"both\" }\n",
        "#@markdown Images have to be normalizated with 255.\n",
        "\n",
        "normalize_params =  None #@param {type:\"number\"}\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train/normalize_params\n",
        "x_test = x_test/normalize_params\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhdFpccbLgZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Expanding dimenstion { form-width: \"400px\", display-mode: \"both\" }\n",
        "#@markdown Convert the (None,28,28) to (None,28,28,1)\n",
        "x_train = x_train[..., tf.newaxis]\n",
        "x_test = x_test[..., tf.newaxis]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-HEj60qIIED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Printing the final input shape ready for training { form-width: \"400px\", display-mode: \"both\" }\n",
        "print(\"Train matrix shape\", x_train.shape)\n",
        "print(\"Test matrix shape\", x_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucsXh8HdIv93",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Making output to be one hot-encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "#@markdown Enter the number of class\n",
        "num_class =  None #@param {type:\"integer\"}\n",
        "Y_hot_enc_train = to_categorical(y_train,num_classes=num_class)\n",
        "Y_hot_enc_test  = to_categorical(y_test,num_classes=num_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9V4CHACNFx7",
        "colab_type": "text"
      },
      "source": [
        "# Compile and train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sMaaxBrI_OX",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Compile our model { vertical-output: true }\n",
        "#@markdown Enter loss function:\n",
        "loss_name   = '' #@param {type:'string'}\n",
        "\n",
        "#@markdown Enter evaluation metric:\n",
        "metric_name = '' #@param {type:'string'}\n",
        "\n",
        "#@markdown Enter Optimizer function:\n",
        "optimization_func = \"sgd\" #@param [\"sgd\", \"adam\"]\n",
        "\n",
        "\n",
        "model.compile(loss=loss_name, \n",
        "              metrics=[metric_name], \n",
        "              optimizer=optimization_func)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLZ-nICkJYg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training our model { vertical-output: true }\n",
        "#@markdown Enter Batchsize:\n",
        "batch_size = None  #@param {type:'integer'}\n",
        "\n",
        "#@markdown Enter number of epoch:\n",
        "n_epochs =  None #@param {type:'integer'}\n",
        "\n",
        "#@markdown ----------------------------------\n",
        "# training the model and saving metrics in history\n",
        "\n",
        "\n",
        "history = model.fit(x_train, Y_hot_enc_train,\n",
        "          batch_size=batch_size, epochs=n_epochs,\n",
        "          verbose=2,\n",
        "          validation_data=(x_test, Y_hot_enc_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFzJ1_aHNS4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Showing Loss { vertical-output: true }\n",
        "import matplotlib.pylab as plt\n",
        "train_loss = history.history['loss']\n",
        "val_loss   = history.history['val_loss']\n",
        "\n",
        "plt.figure()\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"#epoch\")\n",
        "plt.plot(train_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.legend(['train','test'])\n",
        "plt.title('Loss')\n",
        "plt.grid(True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLwado0HQAB_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Showing Accuracy { vertical-output: true }\n",
        "train_acc  = history.history['accuracy']\n",
        "val_acc    = history.history['val_accuracy']\n",
        "plt.figure()\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"#epoch\")\n",
        "plt.plot(train_acc)\n",
        "plt.plot(val_acc)\n",
        "plt.legend(['train','test'])\n",
        "plt.title('Loss')\n",
        "plt.grid(True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf9d9VVrNNdF",
        "colab_type": "text"
      },
      "source": [
        "# Save and Restore Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbpyeTSKJq4k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Save model\n",
        "import time\n",
        "t = time.time()\n",
        "\n",
        "export_path = \"/tmp/saved_models/{}\".format(int(t))\n",
        "tf.saved_model.save(model, export_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2WDDyErUIek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Loading model for prediction\n",
        "reloaded_model = tf.keras.models.load_model(export_path)\n",
        "print(reloaded_model.predict(x_test[:1,:,:,:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzZtAZr_NRTB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Resume for training model again\n",
        "#@markdown Enter loss function:\n",
        "loss_name   = '' #@param {type:'string'}\n",
        "\n",
        "#@markdown Enter evaluation metric:\n",
        "metric_name = '' #@param {type:'string'}\n",
        "\n",
        "#@markdown Enter Optimizer function:\n",
        "optimization_func = \"sgd\" #@param [\"sgd\", \"adam\"]\n",
        "\n",
        "reloaded_model.compile(optimizer=optimization_func,\n",
        "                 loss=loss_name,\n",
        "                 metrics=[metric_name])\n",
        "\n",
        "loss_and_metrics = reloaded_model.evaluate(x_test, \n",
        "                                           Y_hot_enc_test, \n",
        "                                           verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epdzI6s4vkd-",
        "colab_type": "text"
      },
      "source": [
        "# **Feature Map Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XDtWuLIvjxY",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Visualization of feature map { vertical-output: true, form-width: \"50%\" }\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "from   tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "# Let's define a new Model that will take an image as input, and will output\n",
        "# intermediate representations for all layers in the previous model after\n",
        "# the first.\n",
        "successive_outputs = [layer.output for layer in reloaded_model.layers]\n",
        "\n",
        "#visualization_model = Model(img_input, successive_outputs)\n",
        "visualization_model = tf.keras.models.Model(inputs = reloaded_model.input, \n",
        "                                            outputs = successive_outputs)\n",
        "\n",
        "idx = random.randint(0,x_test.shape[0])\n",
        "x = np.array([x_test[idx,:,:,:]])                         # Numpy array with shape (28, 150, 3)\n",
        "\n",
        "\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers]\n",
        "\n",
        "# -----------------------------------------------------------------------\n",
        "# Now let's display our representations\n",
        "# -----------------------------------------------------------------------\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  \n",
        "  if len(feature_map.shape) == 4:\n",
        "    \n",
        "    #-------------------------------------------\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    #-------------------------------------------\n",
        "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
        "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
        "    \n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    \n",
        "    #-------------------------------------------------\n",
        "    # Postprocess the feature to be visually palatable\n",
        "    #-------------------------------------------------\n",
        "    for i in range(n_features):\n",
        "      x  = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std ()\n",
        "      x *=  64\n",
        "      x += 128\n",
        "      x  = np.clip(x, 0, 255).astype('uint8')\n",
        "      display_grid[:, i * size : (i + 1) * size] = x # Tile each filter into a horizontal grid\n",
        "\n",
        "    #-----------------\n",
        "    # Display the grid\n",
        "    #-----------------\n",
        "\n",
        "    scale = 20. / n_features\n",
        "    plt.figure( figsize=(scale * n_features, scale) )\n",
        "    plt.title ( layer_name )\n",
        "    plt.grid  ( False )\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow( display_grid, aspect='auto', cmap='gray' ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5QmhFgfAF2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}