{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Worksheet3_VGG16_Caltech101.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NattachaiWat/ml442/blob/master/Worksheet3_VGG16_Caltech101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBGMlrUHQtk5",
        "colab_type": "text"
      },
      "source": [
        "## Workshop 3.3: Lab experiments\n",
        "\n",
        "## Objectives:\n",
        "\n",
        "    1. Learning about Tensorflow Dataset (Caltech101)\n",
        "    (https://www.tensorflow.org/datasets/catalog/caltech101)\n",
        "    2. Create a VGG using Sequential Model\n",
        "    3. Try to train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-uybaefYUQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Repeat! import tensorflow 2.x again\n",
        "!pip install -q tf-nightly-2.0-preview\n",
        "%load_ext tensorboard\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "\n",
        "tf.keras.backend.clear_session()  # For easy reset of notebook state."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-EeD2gvYpsn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title We have to import tfds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQECMY0fRSwb",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Try to visit caltech101 web  { vertical-output: true }\n",
        "#@markdown http://www.vision.caltech.edu/Image_Datasets/Caltech101/\n",
        "split_train = tfds.Split.TRAIN.subsplit(tfds.percent[:80])\n",
        "split_test  = tfds.Split.TRAIN.subsplit(tfds.percent[-20:])\n",
        "\n",
        "#@markdown Enter dataset name from tfds\n",
        "dataset_name = '' #@param {type:'string'}\n",
        "tfds_train = tfds.load(name=dataset_name, \n",
        "                             split=split_train,\n",
        "                             data_dir='./dataset')\n",
        "tfds_valid   = tfds.load(name=dataset_name,\n",
        "                               split=split_test,\n",
        "                               data_dir='./dataset')\n",
        "tfds_builder = tfds.builder(dataset_name)\n",
        "tfds_info  = tfds_builder.info\n",
        "label_names = tfds_info.features['label'].names\n",
        "nClass = tfds_info.features['label'].num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSFxrdSET8Vx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(type(caltech101_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-F0kb4SbSHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Explore images and label in dataset { vertical-output: true }\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "plt.figure(figsize=(ncols*3,nrows*3))\n",
        "for i,data in enumerate (tfds_train.take(nrows*ncols)):  # Only take a single example\n",
        "  image, label = data[\"image\"], data[\"label\"]\n",
        "  plt.subplot(nrows,ncols,i+1)\n",
        "  plt.imshow(image)\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title('{}:{}'.format(label_names[label],image.shape))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jmYVYKuWNBJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Normalizing and Resizeing image from tf.dataset { vertical-output: true }\n",
        "#@markdown Enter  input size of image\n",
        "resize_img = None #@param \n",
        "#@markdown Hint: 2 dimensions\n",
        "\n",
        "def image_process(data):\n",
        "  img = tf.image.resize(data['image'],size=resize_img)\n",
        "  img = tf.divide(img,255.0)\n",
        "  label = tf.one_hot(data['label'],nClass)\n",
        "  return img,label\n",
        "\n",
        "ds_train = tfds_train.map(image_process)\n",
        "ds_val = tfds_valid.map(image_process)\n",
        "\n",
        "nrows = 3\n",
        "ncols = 3\n",
        "plt.figure(figsize=(ncols*3,nrows*3))\n",
        "for i,data in enumerate (ds_train.take(nrows*ncols)):  # Only take a single example\n",
        "  image, label = data[0], data[1]\n",
        "  label = int(tf.argmax(label).numpy())\n",
        "  plt.subplot(nrows,ncols,i+1)\n",
        "  plt.imshow(image)\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.title('{}:{}'.format(label_names[label],image.shape))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFeiM8d0SlEN",
        "colab_type": "text"
      },
      "source": [
        "## VGG16 as Sequential API\n",
        "\n",
        "Next, we will create a VGG convolutional network. VGG networks are sequential, but they add the concept of convolutional groups. The basic elements of a VGG are:\n",
        "\n",
        "    1. Each convolutional group consists of two or more convolutional layers.\n",
        "    2. Max pooling is deferred to the end of the convolutional group.\n",
        "    3. Each convolutional group is the same or double the number of filters as the last  \n",
        "       group.\n",
        "    4. Multiple dense layers are used for the classifer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQ6W3aZtSXyz",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Construct VGG16 { vertical-output: true }\n",
        "\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "def conv_block(n_layers, n_filters):\n",
        "    \"\"\"\n",
        "        n_layers : number of convolutional layers\n",
        "        n_filters: number of filters\n",
        "    \"\"\"\n",
        "    for n in range(n_layers):\n",
        "        model.add(Conv2D(n_filters, (3, 3), strides=(1, 1), \n",
        "                  padding=\"same\",\n",
        "                  activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(2, strides=2))\n",
        "\n",
        "# Create a Sequential Model\n",
        "model = Sequential()\n",
        "\n",
        "# Add Convolutional Frontend with 64 3x3 filters of stride 1\n",
        "# Set the padding so when the filter is slid over the edges of the image, the \"imaginary\" pixels have the same\n",
        "# value as the pixels on the edge.\n",
        "\n",
        "#@markdown Enter shape of input image\n",
        "input_shape= None #@param \n",
        "model.add(Conv2D(filters=64, \n",
        "          kernel_size=(3,3), strides=(1, 1), \n",
        "          padding='same', activation=\"relu\",\n",
        "          input_shape=input_shape))\n",
        "\n",
        "\n",
        "#@markdown  These are the convolutional groups - double the number of filters on each progressive group\n",
        "\n",
        "#@markdown Enter the number of filter in the first block\n",
        "nfilter_in_block1 = None #@param \n",
        "conv_block(1, nfilter_in_block1)\n",
        "conv_block(2, nfilter_in_block1*2)\n",
        "conv_block(3, nfilter_in_block1*4)\n",
        "\n",
        "#@markdown The last two groups in a VGG16, its double the size of the previous of the group, but both groups are the same size.\n",
        "\n",
        "#@markdown Enter the number of filter in the first block\n",
        "nfilter_in_block2 = None  #@param \n",
        "conv_block(3, nfilter_in_block2*8)\n",
        "conv_block(3, nfilter_in_block2*8)\n",
        "\n",
        "#@markdown  Add DNN Backend with two layers of 4096 nodes\n",
        "# HINT: think of what you need to do to the 2D feature maps from the convolutional layers before passing to dense layers.\n",
        "model.add(Flatten())\n",
        "\n",
        "#@markdown Enter the number of node for fully connect layer\n",
        "num_node1 =  None #@param \n",
        "num_node2 =  None #@param \n",
        "model.add(Dense(num_node1, activation='relu'))\n",
        "model.add(Dense(num_node2, activation='relu'))\n",
        "\n",
        "# Output layer for classification (102 classes)\n",
        "#@markdown Enter the number of class for classification\n",
        "num_class = None #@param \n",
        "#@markdown Enter the activation function for classification\n",
        "final_activation =  None #@param \n",
        "\n",
        "model.add(Dense(num_class, activation=final_activation))\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrX5o00OiqbT",
        "colab_type": "text"
      },
      "source": [
        "# Try to train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rTnoQH1bN77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Compile the model { vertical-output: true }\n",
        "#@markdown Enter loss \n",
        "\n",
        "loss_name = '' #@param {type:'string'}\n",
        "#@markdown Hint: categorical_crossentropy may not work. Why?\n",
        "\n",
        "metric_name = '' #@param {type: 'string'}\n",
        "optimizer_name =  None #@param\n",
        "\n",
        "model.compile(loss=loss_name,  \n",
        "              metrics=[metric_name], \n",
        "              optimizer=optimizer_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3hGgv-Vte1Ae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Training the model in history { form-width: \"350px\" }\n",
        "\n",
        "#@markdown Enter the batch size\n",
        "batch_size = None #@param {type:'integer'}\n",
        "#@markdown Enter the number of epoch\n",
        "epochs = None #@param {type:'integer'}\n",
        "\n",
        "_train = ds_train.batch(batch_size)\n",
        "_val   = ds_val.batch(batch_size)\n",
        "\n",
        "# prefetch will enable the input pipeline to asynchronously fetch batches while\n",
        "# your model is training.\n",
        "_train = _train.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "_val   = _val.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "\n",
        "history = model.fit(_train,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If30iNl_-Jbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}